{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "304c012c-d925-4a5e-8cac-2f46c3e681d6",
   "metadata": {},
   "source": [
    "# Machine Learning Induction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b59438f-c951-4251-90b3-a67876a1dd36",
   "metadata": {},
   "source": [
    "The objective of this notebook is to induce Machine Learning models. For this, tabular datasets (generated using lazy vectorization and embedding techniques) and Machine Learning techniques (both classical and state-of-the-art) will be generated. The evaluation will be performed using hierarchical classification performance metrics.<br>  \n",
    "**Source file:** select_202425091103-translated.csv<br>\n",
    "**Destination file:** select_202425091103-[GPT, Llama, etc].pickle<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e042554-fb0a-4598-bac6-9e9b58e6d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd56b7fd-5afc-4fa1-bdc8-e9c5782cf133",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0486b156-ae31-40b3-b445-29c57729205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnpq = ['cnpq_area_level_1',\n",
    "        'cnpq_area_level_2',\n",
    "        'cnpq_area_level_3',\n",
    "        'cnpq_area_level_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b491f2f8-ffa0-4f13-b85b-78471678358c",
   "metadata": {},
   "source": [
    "## Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aa240a-d617-4a49-9ab2-ec5a0c376a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d145d2de-6fce-4eee-b472-66bceb581bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/select_202425091103-translated.csv', dtype=str, na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6756b5-b2eb-4400-9e81-280648251d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded8c9bf-663c-45d4-854f-2ea8466cab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba9d3fe-878c-4db0-91a0-05bdea6343a5",
   "metadata": {},
   "source": [
    "## Loading the Transformation Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73dc04f-772b-4c93-a7ad-adaab98a9f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/embedding.py\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class Normalizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.stemmer = PorterStemmer()\n",
    "\n",
    "    def pre_processing(self, doc):\n",
    "        pattern = re.compile(r'\\d+|http\\S+|<.*?>', re.IGNORECASE)\n",
    "        return pattern.sub('', doc).lower()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return [' '.join(self.stemmer.stem(word) for word in word_tokenize(self.pre_processing(doc))) for doc in X]\n",
    "\n",
    "class Lazy(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, vectorizer, ngram_range, max_df, min_df, max_features):\n",
    "        self.vectorizer = vectorizer(ngram_range=ngram_range, max_df=max_df, min_df=min_df, max_features=max_features)\n",
    "        self.ngram_range = ngram_range\n",
    "        self.max_df = max_df\n",
    "        self.min_df = min_df\n",
    "        self.max_features = max_features\n",
    "\n",
    "    def fit(self, raw_documents, y=None):\n",
    "        self.vectorizer.fit(raw_documents, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, raw_documents):\n",
    "        return self.vectorizer.transform(raw_documents).toarray()\n",
    "\n",
    "    def fit_transform(self, raw_documents, y=None):\n",
    "        return self.vectorizer.fit_transform(raw_documents, y).toarray()\n",
    "\n",
    "class BoW(Lazy):\n",
    "    def __init__(self, ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=9000):\n",
    "        super().__init__(CountVectorizer, ngram_range=ngram_range, max_df=max_df, min_df=min_df, max_features=max_features)\n",
    "\n",
    "class TFIDF(Lazy):\n",
    "    def __init__(self, ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=9000):\n",
    "        super().__init__(TfidfVectorizer, ngram_range=ngram_range, max_df=max_df, min_df=min_df, max_features=max_features)\n",
    "\n",
    "class Embedding(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "        self.model = SentenceTransformer('../models/' + model_name)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([self.model.encode(text) for text in X])\n",
    "\n",
    "class RoBERTa(Embedding):\n",
    "    def __init__(self, model_name='all-distilroberta-v1'):\n",
    "        super().__init__(model_name=model_name)\n",
    "\n",
    "class USE(Embedding):\n",
    "    def __init__(self, model_name='distiluse-base-multilingual-cased-v1'):\n",
    "        super().__init__(model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44624e49-555b-413d-a5ce-a333fae18566",
   "metadata": {},
   "source": [
    "## Loading the SVM wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985a86ee-ce74-4d33-abeb-e3896d4bec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/svm.py\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "class SVM(SVC):\n",
    "    def __init__(self, C=1.0, kernel='rbf', probability=True):\n",
    "        super().__init__(C=C, kernel=kernel, probability=probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00641db9-b4ea-41e4-8b64-cde0914593cc",
   "metadata": {},
   "source": [
    "## Loading the GPTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f931b88-ae28-4bf0-b673-306ac1d0190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/gpt_classifier.py\n",
    "import random, openai, json\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "class GPTClassifier(BaseEstimator):\n",
    "\n",
    "    def __init__(self, model, key):\n",
    "        self.model = model\n",
    "        self.key = key\n",
    "        openai.api_key = self.key\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = unique_labels(y)\n",
    "        self.labels_ = [item.split('::HiClass::Separator::')[-1] for item in self.classes_.tolist()]\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for text in X:\n",
    "\n",
    "            pred = ''\n",
    "            text = (f'Classify the article content into one correct research area:\\n {text}')\n",
    "            completion = openai.chat.completions.create(\n",
    "                model = self.model,\n",
    "                messages = [{'role': 'user', 'content': text}],\n",
    "                tools = self.classify_content(self.labels_),\n",
    "                tool_choice = {'type': 'function', 'function': {'name': 'classify_content'}}\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                content = completion.choices[0].message.tool_calls[0].function.arguments\n",
    "                pred = json.loads(content)['prediction'][0]\n",
    "                idx = self.labels_.index(pred)\n",
    "            except:  \n",
    "                pred = random.choice(self.labels_)\n",
    "                idx = self.labels_.index(pred)\n",
    "\n",
    "            predictions.append(self.classes_[idx])\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def classify_content(self, labels):\n",
    "\n",
    "        return [{\n",
    "                'type': 'function',\n",
    "                'function': {\n",
    "                    'name': 'classify_content',\n",
    "                    'description': 'Predict the research area for a given article content',\n",
    "                    'parameters': {\n",
    "                        'type': 'object',\n",
    "                        'properties': {\n",
    "                            'prediction': {\n",
    "                                'type': 'array',\n",
    "                                'items': {\n",
    "                                    'type': 'string',\n",
    "                                    'enum': labels\n",
    "                                },\n",
    "                                'description': 'The predicted reserach areas.'\n",
    "                            }\n",
    "                        },\n",
    "                        'required': [\n",
    "                            'prediction'\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "        }]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c09469e-6fb1-4405-9482-cb66e21bf2f8",
   "metadata": {},
   "source": [
    "## Loading the OllamaClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df72a22c-050c-427f-827c-1b46a4c0d1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/ollama_classifier.py\n",
    "import json, random\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "class OllamaClassifier(BaseEstimator):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = ChatOllama(model=model, format='json')\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = unique_labels(y)\n",
    "        self.labels_ = [item.split('::HiClass::Separator::')[-1] for item in self.classes_.tolist()]\n",
    "        self.template = ChatPromptTemplate.from_template(\"\"\"\n",
    "                Based on the article content:\\n\\n\n",
    "                {text}\\n\\n\n",
    "                Classify the content into one correct research area:\n",
    "                {labels}\n",
    "                Return a JSON object like ['Research Area': ''].\"\"\"\n",
    "            ) | self.model\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for text in X:\n",
    "\n",
    "            pred = ''\n",
    "            self.classify_content(self.labels_)\n",
    "            content = self.template.invoke({'text': text, 'labels': '; '.join(self.labels_)})\n",
    "\n",
    "            try:\n",
    "                content = content.dict()\n",
    "                pred = json.loads(content['content'])['Research Area']\n",
    "                idx = self.labels_.index(pred)\n",
    "            except:  \n",
    "                pred = random.choice(self.labels_)\n",
    "                idx = self.labels_.index(pred)\n",
    "\n",
    "            predictions.append(self.classes_[idx])\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "        \n",
    "    def classify_content(self, labels):\n",
    "\n",
    "        self.model = self.model.bind(\n",
    "            tools = [{\n",
    "                'name': 'classify_content',\n",
    "                'description': 'Predict the research area for a given article content',\n",
    "                'parameters': {\n",
    "                    'type': 'object',\n",
    "                    'properties': {\n",
    "                        'prediction': {\n",
    "                            'type': 'array',\n",
    "                            'description': 'The predicted reserach areas.',\n",
    "                            'items': {\n",
    "                                'type': 'string',\n",
    "                                'enum': labels\n",
    "                            },\n",
    "                        }\n",
    "                    },\n",
    "                    'required': ['prediction']\n",
    "                }\n",
    "            }], \n",
    "            function_call={'name': 'classify_content'}\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef62209-b53e-402d-a052-a45242f62dcc",
   "metadata": {},
   "source": [
    "## Loading the FlatClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca109b3e-ccd7-4bfa-8639-2abca5e475ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/flat_classifier.py\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class FlatClassifier(BaseEstimator):\n",
    "\n",
    "    def __init__(self, local_classifier):\n",
    "        self.local_classifier = local_classifier \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y = [\"::HiClass::Separator::\".join(i) for i in y]\n",
    "        self.local_classifier.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return [i.split('::HiClass::Separator::') for i in self.local_classifier.predict(X)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e6abd4-8155-4f91-b1c1-40479dcd7423",
   "metadata": {},
   "source": [
    "## Loading the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a0c892-ce9a-4556-8b44-b833030bc59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/evaluate.py\n",
    "from hiclass.metrics import precision, recall, f1\n",
    "\n",
    "def accuracy_class(y_true, y_pred, level):\n",
    "\n",
    "    total, hits = defaultdict(int), defaultdict(int)\n",
    "\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "\n",
    "        total[t[level]] += 1\n",
    "        if t[level] == p[level]:\n",
    "            hits[t[level]] += 1\n",
    "\n",
    "    return {classe: hits[classe] / total[classe] for classe in total}\n",
    "\n",
    "def accuracy_unit(units, true, pred, level):\n",
    "\n",
    "    acc = []\n",
    "    for unit in set(units):\n",
    "        true_vals = [t[level] for u, t in zip(units, true) if u == unit]\n",
    "        pred_vals = [p[level] for u, p in zip(units, pred) if u == unit]\n",
    "        acc.append((unit, true_vals, pred_vals))\n",
    "\n",
    "    return acc\n",
    "\n",
    "def accuracy_level(y_true, y_pred, level):\n",
    "    acc = [(1 if true[level] == '' or true[level] == pred[level] else 0) for true, pred in zip(y_true, y_pred)]\n",
    "    return sum(acc)/len(acc)\n",
    "\n",
    "def flatly(y_true, y_pred):\n",
    "    return {'Level ' + str(level) : accuracy_level(y_true, y_pred, level) for level in range(4)}\n",
    "\n",
    "def hierarchy(y_true, y_pred, type='micro'):\n",
    "    return {'F1-score': f1(y_true, y_pred, type),\n",
    "            'Precision': precision(y_true, y_pred, type),\n",
    "            'Recall': recall(y_true, y_pred, type)}\n",
    "\n",
    "def performance(y_true, y_pred):\n",
    "    return hierarchy(y_true, y_pred) | flatly(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77826c07-5d96-46df-9b8d-1b0cdd2d7939",
   "metadata": {},
   "source": [
    "## Splitting training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5953ca8d-e512-480f-8db8-5c8be233c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, gzip, tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255107a9-abca-46b9-9f09-a94ea14a3e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(config, result):\n",
    "    for key, value in result.items():\n",
    "        with gzip.open('../' + key + '/select_202425091103-' + config + '.pickle', 'wb') as handle:\n",
    "            pickle.dump(value, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc417a92-2023-475f-a65d-66f70906119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['all'].to_numpy(), df[cnpq].to_numpy(), test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b682c436-75ed-4a80-b476-0543c424aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b572bb8e-7a61-478f-8583-927b3a6d2d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11384a16-e2af-4738-9e2d-a6cd2a7dc0f1",
   "metadata": {},
   "source": [
    "## Executing the classical pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4fa5c2-8283-4c4f-b1fb-1209f1fc8b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from itertools import product\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from hiclass import LocalClassifierPerNode, LocalClassifierPerParentNode, LocalClassifierPerLevel\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d38fb7-2238-4fb1-8df8-d2d6db73b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = {'BoW' : BoW,\n",
    "                'TFIDF' : TFIDF,\n",
    "                'RoBERTa' : RoBERTa,\n",
    "                'USE' : USE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d2bc98-9936-4721-8060-fcab3cc81271",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = {'LCPN' : LocalClassifierPerNode, \n",
    "              'LCPPN' : LocalClassifierPerParentNode, \n",
    "              'LCPL' : LocalClassifierPerLevel,\n",
    "              'FLAT' : FlatClassifier}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa92204-00e0-4610-99f5-f78475d2362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {'DT' : DecisionTreeClassifier, \n",
    "               'RF' : RandomForestClassifier,\n",
    "               'NB' : GaussianNB,\n",
    "               'SVM' : SVM}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372f6d1d-067a-4479-be12-d5d9f608e658",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for tfm, stg, cls in tqdm.tqdm(product(transformers, strategies, classifiers)):\n",
    "\n",
    "    steps = []\n",
    "    if tfm in ['BoW', 'TFIDF']:\n",
    "        steps.append(('', Normalizer()))\n",
    "\n",
    "    steps.append((tfm, transformers[tfm]()))\n",
    "    steps.append((stg + ' ' + cls, strategies[stg](classifiers[cls]())))\n",
    "    \n",
    "    pipeline = Pipeline(steps) \n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    pred = pipeline.predict(X_test)\n",
    "    result = {'results' : performance(y_test, pred), 'models' : pipeline}\n",
    "    config = ' '.join(list(pipeline.named_steps.keys()))\n",
    "    save(config, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79b2d23-64a0-4042-93e3-e840676c6422",
   "metadata": {},
   "source": [
    "## Executing the language model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188aeb4b-73f8-4061-a3e9-783b6cc2ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_sklearn import BertClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e0fa71-1133-40df-8673-6e5e2566f92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = {'LCPPN' : LocalClassifierPerParentNode}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee6f24e-f400-4e4a-a2da-17be05a5cee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {'GPT' : GPTClassifier('gpt-4o', openai_key), \n",
    "               'Llama' : OllamaClassifier('llama3.1:70b'),\n",
    "               'BERT' : BertClassifier('bert-base-uncased', epochs=4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee77419f-3619-4001-8220-5442ef5e256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stg, cls in tqdm.tqdm(product(strategies, classifiers)):\n",
    "\n",
    "    steps = []\n",
    "    steps.append((stg + ' ' + cls, strategies[stg](classifiers[cls], bert=True)))\n",
    "    \n",
    "    pipeline = Pipeline(steps) \n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    pred = pipeline.predict(X_test)\n",
    "    result = {'results' : performance(y_test, pred), 'models' : pipeline}\n",
    "    config = ' '.join(list(pipeline.named_steps.keys()))\n",
    "    save(config, result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
